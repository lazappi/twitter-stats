---
title: "Twitter coverage of the 2018 COMBINE Symposium"
author: "Luke Zappia"
date: "`r Sys.time()`"
output: 
  html_document: 
    number_sections: yes
    toc: yes
    toc_float: yes
---

```{r knitr, include = FALSE}
DOCNAME <- tools::file_path_sans_ext(knitr::current_input())
knitr::opts_chunk$set(autodep        = TRUE,
                      cache          = FALSE,
                      cache.path     = paste0("cache/", DOCNAME, "/"),
                      cache.comments = TRUE,
                      echo           = FALSE,
                      error          = FALSE,
                      fig.align      = "center",
                      fig.path       = paste0("figures/", DOCNAME, "/"),
                      fig.width      = 10,
                      fig.height     = 8,
                      message        = FALSE,
                      warning        = FALSE)
```

```{r libraries, include = FALSE}
# Twitter
library("rtweet")

# Data manipulation
library("dplyr")
library("tidyr")
library("lubridate")
library("forcats")
library("purrr")
library("stringr")

# Text analysis
library("tidytext")
library("topicmodels")

# Graphs
library("igraph")

# Visualisation
library("ggplot2")
library("ggrepel")
library("wordcloud")
library("ggraph")
library("viridis")

# Presentation
library("knitr")

# Here
library("here")
```

```{r params}
set.seed(1)

hashtag <- "#COMBINE18"
conf_name <- "COMBINE Symposium 2018"
timezone <- "Australia/Melbourne"
days <- c("2018-11-26")
accent <- "#4a86e8"
pal <- "Set1"
kcore <- 2
topics_k <- 3
bigram_filter <- 3
fixed <- FALSE # Set to TRUE to stop adding new tweets

params <- data.frame(Parameter = c("Hashtag", "Conference", "Time Zone", "Days",
                                   "Accent colour", "Pallete", "k-core",
                                   "Topics k", "Bigram filter", "Fixed"))
params_list <- list(hashtag, conf_name, timezone, days, accent, pal, kcore, 
                    topics_k, bigram_filter, fixed)
params$Value <- params_list
```

**Parameters**

`r kable(params)`

```{r load, include = FALSE}
theme_set(theme_light())

data_file <- here("data", paste0(DOCNAME, ".Rds"))

if (fixed) {
    if (file.exists(data_file)) {
        tweets <- readRDS(data_file)
    } else {
        stop("fixed is TRUE but no data file exists", call. = FALSE)
    }
} else {
    if (file.exists(data_file)) {
        existing_tweets <- readRDS(data_file)
        message(nrow(existing_tweets), " tweets already downloaded")
        
        new_tweets <- search_tweets(hashtag, 10000) %>%
            mutate(collected_at = Sys.time())
        message("Found ", nrow(new_tweets), " new tweets")
        
        tweets <- new_tweets %>%
            rbind(existing_tweets) %>%
            group_by(status_id) %>%
            top_n(1, collected_at) %>%
            ungroup()
    } else {
        tweets <- search_tweets(hashtag, 10000) %>%
            mutate(collected_at = Sys.time())
        message("Found ", nrow(tweets), " tweets")
    }
    saveRDS(tweets, data_file)
}
```

# Introduction
An analysis of tweets from the `r conf_name` conference. A total of
`r nrow(tweets)` tweets from `r length(unique(tweets$screen_name))` users were 
collected using the `rtweet` R package.

# Timeline

## Tweets by day

```{r tweets-by-day}
tweets %>% 
    mutate(date = as_date(created_at, tz = timezone)) %>% 
    count(date) %>% 
    ggplot(aes(date, n)) + geom_col(fill = accent) +  
        labs(x = "Date", y = "Tweets",
             title = paste(hashtag, "tweets per day")) + 
        theme(axis.text = element_text(size = 12),
              axis.title = element_text(size = 12))
```

## Tweets by day and time

Filtered for dates `r min(days)` - `r max(days)` in the `r timezone` timezone.

```{r tweets-by-day-hour, eval = Sys.Date() >= min(days)}
tweets_days <- tweets %>% 
    mutate(datetime = as_datetime(created_at, tz = timezone),
         hour = hour(datetime)) %>% 
    group_by(date = as_date(datetime), hour) %>% 
    filter(date >= as_date(min(days)), date <= as_date(max(days)))

tweets_days %>%
    summarise(count = n()) %>% 
    ggplot(aes(hour, count)) +
        geom_col(fill = accent) +
        facet_grid(strftime(date, "%b %d") ~ .) + 
        labs(x = "Hour", y = "Tweets",
             title = paste(hashtag, "tweets by time of day")) + 
        theme(axis.text = element_text(size = 12),
              axis.title = element_text(size = 12))
```

# Users

## Top tweeters

```{r tweets-top-users}
tweets %>% 
    count(screen_name) %>% 
    arrange(desc(n)) %>%
    slice(1:20) %>% 
    ggplot(aes(reorder(screen_name, n), n)) +
        geom_col(fill = accent) +
        coord_flip() + 
        labs(x = "Screen Name", y = "Tweets",
             title = paste(hashtag, "tweets by user"),
             subtitle = "top 20 users") + 
        theme(axis.text = element_text(size = 12),
              axis.title = element_text(size = 12))
```

## Top original tweeters

```{r tweets-top-users-orig}
tweets %>%
    filter(is_retweet == FALSE) %>%
    count(screen_name) %>% 
    arrange(desc(n)) %>%
    slice(1:20) %>% 
    ggplot(aes(reorder(screen_name, n), n)) +
        geom_col(fill = accent) +
        coord_flip() + 
        labs(x = "Screen Name", y = "Tweets",
             title = paste(hashtag, "tweets by user"),
             subtitle = "top 20 users (no retweets)") + 
        theme(axis.text = element_text(size = 12),
              axis.title = element_text(size = 12))
```

## Retweet proportion

```{r tweets-retweet-prop}
plot_data <- tweets %>%
    group_by(screen_name) %>%
    summarise(orig = sum(!is_retweet),
              retweet = sum(is_retweet)) %>%
    mutate(total = orig + retweet)

ggplot(plot_data, aes(total, (orig / total) - (retweet / total))) +
    geom_hline(yintercept = 0, colour = "red") +
    geom_point(colour = accent) +
    geom_text_repel(data = top_n(plot_data, 10, total), 
                    aes(label = screen_name)) +
    labs(x = "Total tweets",
         y = "<<< more retweets : more original tweets >>>",
         title = paste(hashtag, "original tweets compared to retweets"),
         subtitle = "top 10 users labelled") + 
    theme(axis.text = element_text(size = 12),
          axis.title = element_text(size = 12))
```

## Top tweeters by time

```{r tweets-top-users-time}
top_users <- tweets %>%
    count(screen_name) %>% 
    arrange(desc(n)) %>%
    slice(1:5) %>%
    pull(screen_name) %>%
    fct_inorder()

tweets %>%
    filter(screen_name %in% top_users) %>%
    mutate(screen_name = factor(screen_name,
                                levels = levels(top_users))) %>%
    mutate(datetime = as_datetime(created_at, tz = timezone)) %>%
    ggplot(aes(datetime, 1, shape = is_retweet, colour = screen_name)) +
        geom_jitter(width = 0, height = 1) +
        scale_color_brewer(palette = pal, guide = FALSE) +
        facet_wrap(~ screen_name, ncol = 1) +
        labs(x = "Datetime",
             title = paste(hashtag, "top users timeline"),
             subtitle = "when the top 5 users tweeted") + 
        theme(axis.text = element_text(size = 12),
              axis.title = element_text(size = 12),
              axis.title.y = element_blank(),
              axis.text.y = element_blank(),
              axis.ticks.y = element_blank(),
              legend.position = "bottom")
```

## Top tweeters by day

### All tweets {.tabset}

```{r tweets-top-users-days, results = "hide", eval = Sys.Date() >= min(days)}
plot_list <- lapply(seq_along(days), function(ind) {
    tweets_days %>% 
        filter(date == as_date(days[ind])) %>%
        ungroup() %>%
        count(screen_name) %>% 
        arrange(desc(n)) %>%
        slice(1:20) %>% 
        ggplot(aes(reorder(screen_name, n), n)) +
            geom_col(fill = accent) +
            coord_flip() +
            labs(x = "Screen Name", y = "Tweets",
                 title = paste(hashtag, "tweets by user, Day", ind),
                 subtitle = "top 20 users") + 
            theme(axis.text = element_text(size = 12),
                  axis.title = element_text(size = 12))
})

src_list <- lapply(seq_along(plot_list), function(ind) {
    src <- c("#### Day {{ind}} {.unnumbered}",
             "```{r tweets-top-users-day{{ind}}}",
             "plot_list[[{{ind}}]]",
             "```",
             "")
    knit_expand(text = src)
})

out <- knit_child(text = unlist(src_list))
```

`r if (Sys.Date() >= min(days)) out`

### Original tweets {.tabset}

```{r tweets-top-users-orig-days, results = "hide", eval = Sys.Date() >= min(days)}
plot_list <- lapply(seq_along(days), function(ind) {
    tweets_days %>% 
        filter(date == as_date(days[ind])) %>%
        ungroup() %>%
        filter(is_retweet == FALSE) %>%
        count(screen_name) %>% 
        arrange(desc(n)) %>%
        slice(1:20) %>% 
        ggplot(aes(reorder(screen_name, n), n)) +
            geom_col(fill = accent) +
            coord_flip() +
            labs(x = "Screen Name", y = "Tweets",
                 title = paste(hashtag, "tweets by user, Day", ind),
                 subtitle = "top 20 users (no retweets)") + 
            theme(axis.text = element_text(size = 12),
                  axis.title = element_text(size = 12))
})

src_list <- lapply(seq_along(plot_list), function(ind) {
    src <- c("#### Day {{ind}} {.unnumbered}",
             "```{r tweets-top-users-orig-day{{ind}}}",
             "plot_list[[{{ind}}]]",
             "```",
             "")
    knit_expand(text = src)
})

out <- knit_child(text = unlist(src_list))
```

`r if (Sys.Date() >= min(days)) out`

## Sources

```{r tweets-top-sources}
tweets %>% 
    distinct(screen_name, source) %>%
    count(source) %>% 
    filter(n >= 5) %>% 
    ggplot(aes(reorder(source, n), n)) +
        geom_col(fill = accent) +
        coord_flip() + 
        labs(x = "Source", y = "Tweets",
             title = paste(hashtag, "tweets by source"),
             subtitle = "distinct(screen_name, source) with >= 5 tweets") + 
        theme(axis.text = element_text(size = 12),
              axis.title = element_text(size = 12))
```

# Networks

## Replies

The "replies network", composed from users who reply directly to one another, 
coloured by page rank.

```{r reply-network, eval = sum(!is.na(tweets$reply_to_screen_name)) > 5}
tweets_replies <- tweets %>% 
    filter(!is.na(reply_to_screen_name)) %>% 
    select(screen_name, reply_to_screen_name) %>% 
    graph.data.frame(directed = TRUE)

V(tweets_replies)$label <- V(tweets_replies)$name
V(tweets_replies)$id    <- V(tweets_replies)$name
V(tweets_replies)$pr    <- page_rank(tweets_replies)$vector

ggraph(tweets_replies, layout = "fr") +
    geom_edge_link(arrow = arrow(length = unit(4, 'mm')), 
                   end_cap = circle(1, 'mm'),
                   colour = "darkgrey") +
    geom_node_point(aes(colour = pr)) +
    geom_node_text(aes(label = label), colour = accent, repel = FALSE) +
    viridis::scale_colour_viridis() +
    theme_graph() +
    theme(legend.position = "none")
```

## Mentions

The "mentions network", where users mention other users in their tweets.
Filtered for a k-core of `r kcore`. Node colour and size adjusted according to 
PageRank score.

```{r mentions-network}
tweets_mentions <- tweets %>% 
    filter(!is.na(mentions_screen_name)) %>% 
    select(screen_name, mentions_screen_name) %>% 
    unnest(mentions_screen_name) %>% 
    mutate(mentions_screen_name = strsplit(mentions_screen_name, " ")) %>% 
    unnest(mentions_screen_name) %>% 
    graph.data.frame()

V(tweets_mentions)$label <- V(tweets_mentions)$name
V(tweets_mentions)$id    <- V(tweets_mentions)$name
V(tweets_mentions)$pr    <- page_rank(tweets_mentions)$vector
V(tweets_mentions)$kcore <- coreness(tweets_mentions)

lo_kcore <- V(tweets_mentions)$kcore < kcore

tweets_mentions <- delete_vertices(tweets_mentions,
                                   V(tweets_mentions)[lo_kcore])

ggraph(tweets_mentions, layout = "fr") +
    geom_edge_link(arrow = arrow(length = unit(2, 'mm')), 
                   end_cap = circle(1, 'mm'),
                   width = 0.1, colour = "darkgrey") +
    geom_node_point(aes(colour = pr)) +
    geom_node_text(aes(label = label, size = pr,),
                   colour = accent, repel = FALSE) +
    scale_colour_viridis() +
    theme_graph() +
    theme(legend.position = "none")
```

# Retweets

## Retweet proportion

```{r is-retweet}
tweets %>% 
    count(is_retweet) %>% 
    ggplot(aes(is_retweet, n)) + geom_col(fill = accent) + 
        labs(x = "Is retweet", y = "Tweets",
             title = paste(hashtag, "tweets by retweet status")) + 
        theme(axis.text = element_text(size = 12),
              axis.title = element_text(size = 12))
```

## Retweet count

```{r retweet-count}
tweets %>% 
    ggplot(aes(retweet_count)) +
        geom_histogram(bins = max(tweets$retweet_count), fill = accent) +
        labs(x = "Retweet count", y = "Tweets",
             title = paste(hashtag, "distribution of retweets per tweet")) + 
        theme(axis.text = element_text(size = 12),
              axis.title = element_text(size = 12))
```

## Top retweets

```{r most-retweeted}
tweets %>% 
    filter(is.na(retweet_status_id)) %>% 
    select(screen_name, text, retweet_count) %>% 
    arrange(desc(retweet_count)) %>% 
    distinct() %>%
    slice(1:10) %>% 
    kable(format = "html")
```

# Favourites

## Favourite proportion

```{r has-favorite}
tweets %>% 
    mutate(has_favorite = ifelse(favorite_count > 0, TRUE, FALSE)) %>% 
    count(has_favorite) %>%
    ggplot(aes(has_favorite, n)) + geom_col(fill = accent) + 
        labs(x = "Has favorite", y = "Tweets",
             title = paste(hashtag, "tweets by favorited status")) + 
        theme(axis.text = element_text(size = 12),
              axis.title = element_text(size = 12))
```

## Favourite count

```{r favorite-count}
tweets %>% 
    ggplot(aes(favorite_count)) +
        geom_histogram(bins = max(tweets$favorite_count), fill = accent) +
        labs(x = "Favorite count", y = "Tweets",
             title = paste(hashtag, "distribution of favorites per tweet")) + 
        theme(axis.text = element_text(size = 12),
              axis.title = element_text(size = 12))
```

## Top favourites

```{r most-favorited}
tweets %>% 
    select(screen_name, text, favorite_count) %>% 
    arrange(desc(favorite_count)) %>% 
    distinct() %>%
    slice(1:10) %>% 
    kable(format = "html")
```

# Quotes

## Quote proportion

```{r is-quote}
tweets %>% 
    count(is_quote) %>% 
    ggplot(aes(is_quote, n)) +
        geom_col(fill = accent) + 
        labs(x = "Is quote", y = "Tweets",
             title = paste(hashtag, "tweets by quote status")) + 
        theme(axis.text = element_text(size = 12),
              axis.title = element_text(size = 12))
```

## Quote count

```{r quotes-count}
tweets %>% 
    filter(!is.na(quoted_status_id)) %>% 
    count(quoted_status_id) %>% 
    ggplot(aes(n)) + geom_histogram(bins = 10, fill = accent) +
        labs(x = "Quote count", y = "Tweets",
             title = paste(hashtag, "distribution of quotes per tweet")) + 
        scale_x_continuous(limits = c(0, 10), breaks = seq(0, 10, 2)) + 
        theme(axis.text = element_text(size = 12),
              axis.title = element_text(size = 12))
```

## Top quotes

```{r most-quoted}
tweets %>% 
    filter(!is.na(quoted_status_id)) %>% 
    count(quoted_status_id) %>% 
    filter(n > 1) %>% 
    arrange(desc(n)) %>% 
    inner_join(select(tweets, screen_name, quoted_status_id,
                    is_retweet, text)) %>% 
    filter(is_retweet == FALSE) %>% 
    select(screen_name, text, quote_count = n) %>%
    distinct() %>%
    slice(1:10) %>%
    kable(format = "html")
```

# Media

## Media count

```{r has-media}
tweets %>% 
    mutate(has_media = !is.na(media_url)) %>% 
    count(has_media) %>% 
    ggplot(aes(has_media, n)) +
        geom_col(fill = accent) + 
        labs(x = "Has media", y = "Tweets",
             title = paste(hashtag, "tweets by media status")) + 
        theme(axis.text = element_text(size = 12),
              axis.title = element_text(size = 12))
```

## Top media

```{r liked-media}
tweets_media <- tweets %>% 
    filter(!is.na(media_url)) %>% 
    arrange(desc(favorite_count)) %>%
    filter(favorite_count > 0)

tweets_media %>%
    slice(1:10) %>% 
    select(screen_name, text, favorite_count) %>%
    kable(format = "html")
```

### Most liked media image

![](`r tweets_media[1, "media_url"]`)

# Tweet text

## Word cloud

The top 100 words used 3 or more times.

```{r count-words}
data("stop_words")

tweets %>% 
    filter(is_retweet == FALSE) %>% 
    unnest_tokens(word, text) %>% 
    select(word) %>% 
    filter(!word %in% c(gsub("#", "", tolower(hashtag)),
                        "https", "t.co", "amp"),
           !word %in% tolower(tweets$screen_name), 
           !grepl("^\\d+$", word)) %>% 
    anti_join(stop_words, by = "word") %>%
    count(word) %>% 
    with(wordcloud(word, n, max.words = 100, min.freq = 3,
                 colors = brewer.pal(6, "Spectral")))
```

## Bigram graph

Words that were tweeted next to each other at least `r bigram_filter` times.

```{r bigram-graph}
tweets %>% 
    filter(is_retweet == FALSE) %>%
    select(text) %>%
    unnest_tokens(bigram, text, token = "ngrams", n = 2) %>%
    separate(bigram, c("word1", "word2"), sep = " ") %>%
    filter(!word1 %in% stop_words$word,
           !word1 %in% c(gsub("#", "", tolower(hashtag)),
                         "https", "t.co", "amp"),
           !word1 %in% tolower(tweets$screen_name), 
           !grepl("^\\d+$", word1)) %>%
    filter(!word2 %in% stop_words$word,
           !word2 %in% c(gsub("#", "", tolower(hashtag)),
                         "https", "t.co", "amp"),
           !word2 %in% tolower(tweets$screen_name), 
           !grepl("^\\d+$", word2)) %>%
    count(word1, word2, sort = TRUE) %>%
    filter(n >= bigram_filter) %>%
    graph_from_data_frame() %>%
    ggraph(layout = "fr") +
        geom_edge_link(aes(edge_colour = n),
                       arrow = arrow(type = "closed",
                                     length = unit(2, 'mm')),
                       end_cap = circle(1, 'mm')) +
        geom_node_point(size = 2, colour = accent) +
        geom_node_text(aes(label = name), vjust = 1, hjust = 0.5,
                       repel = TRUE, segment.colour = "pink") +
        scale_edge_color_gradientn(colours = viridis(100)) +
        theme_graph()
```

## Topic modelling

Top 10 words associated with `r topics_k` topics identified by LDA.

```{r topic-modelling}
topics <- tweets %>% 
    filter(is_retweet == FALSE) %>%
    select(document = status_id, text) %>%
    unnest_tokens(word, text) %>%
    filter(!word %in% stop_words$word,
           !word %in% c(gsub("#", "", tolower(hashtag)),
                        "https", "t.co", "amp"),
           !word %in% tolower(tweets$screen_name), 
           !grepl("^\\d+$", word)) %>%
    count(document, word, sort = TRUE) %>%
    ungroup() %>%
    cast_dtm(document, word, n) %>%
    LDA(k = topics_k, control = list(seed = 1))
```

```{r topics-words}
topics %>%
    tidy(matrix = "beta") %>%
    group_by(topic) %>%
    top_n(10, beta) %>%
    ungroup() %>%
    arrange(topic, -beta) %>%
    mutate(term = reorder(term, beta)) %>%
    ggplot(aes(x = term, y = beta, fill = factor(topic))) +
        geom_col(show.legend = FALSE) +
        scale_fill_brewer(palette = pal) +
        facet_wrap(~ topic, scales = "free") +
        coord_flip() +
        labs(y = "beta (occurence in topics)",
             title = "Topic modelling",
             subtitle = paste("Top terms for", topics_k,
                              "LDA topics associated with", hashtag)) + 
        theme(axis.text = element_text(size = 12),
              axis.title = element_text(size = 12),
              axis.title.y = element_blank())
```

### Representative tweets {.tabset}

Most representative tweets for each topic

```{r topics-tweets, results = "hide"}
topics_list <- topics %>%
    tidy(matrix = "gamma") %>%
    group_by(document) %>%
    top_n(1, gamma) %>%
    ungroup() %>%
    group_by(topic) %>%
    top_n(10, gamma) %>%
    arrange(-gamma) %>%
    left_join(tweets, by = c(document = "status_id")) %>%
    select(topic, screen_name, text, gamma) %>%
    split(.$topic)
    
src_list <- lapply(seq_along(topics_list), function(ind) {
    src <- c("#### Topic {{ind}} {.unnumbered}",
             "```{r topics-tweets-topic{{ind}}}",
             "kable(topics_list[[{{ind}}]], format = 'html')",
             "```",
             "")
    knit_expand(text = src)
})

out <- knit_child(text = unlist(src_list))
```

`r out`

# Software

Software mentioned in Tweets with links to GitHub, Bioconductor or CRAN.

```{r software}
urls <- discard(tweets$urls_expanded_url, ~ all(is.na(.x))) %>%
    flatten_chr() %>%
    unique()

regexes <- list(
    c(Type = "GitHub",
      re = "http[s]?://github.com/[\\w-]+/([\\w-]+).*"),
    c(Type = "Bioconductor",
      re = "https://bioconductor.org/packages.*/(\\w+).*"),
    c(Type = "CRAN",
      re = "https://cran.*/packages/(\\w+).*")
)

software <- map_df(regexes, function(re) {
    urls %>%
        str_match(re["re"]) %>%
        as_tibble() %>%
        rename(URL = V1, Name = V2) %>%
        mutate(Type = re["Type"])
})

software <- software %>%
    drop_na() %>%
    mutate(
        Link = case_when(
            Type == "GitHub" ~ str_to_lower(str_replace(URL, "http:", "https:")),
            Type == "Bioconductor" ~ paste0("https://bioconductor.org/packages/", Name),
            Type == "CRAN" ~ paste0("https://CRAN.R-project.org/package=", Name),
            TRUE ~ URL
        )
    ) %>%
    select(-URL) %>%
    distinct() %>%
    arrange(Name)
```

`r if (nrow(software) >= 1) kable(software)`

# Session info {.unnumbered}

```{r session-info}
devtools::session_info()
```

